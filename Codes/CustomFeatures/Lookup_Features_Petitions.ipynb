{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function computes ratio of biased words in a petition\n",
    "\n",
    "import numpy\n",
    "bias = numpy.loadtxt(\"bias-lexicon.txt\", dtype=\"string\")\n",
    "\n",
    "def getbias(tokens):\n",
    "    biasc = 0\n",
    "    biasl = set(bias.tolist())\n",
    "    for i in tokens:\n",
    "        x = i.lower()\n",
    "        if x in biasl:\n",
    "            biasc += 1\n",
    "    return (biasc*1.0)/len(set(tokens))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function computes ratio of indefinite and definite articles\n",
    "\n",
    "def getarticles(tokens):\n",
    "    defa = 0\n",
    "    indefa = 0\n",
    "    for i in tokens:\n",
    "        x = i.lower()\n",
    "        if x == 'a' or x == 'an':\n",
    "            defa +=1\n",
    "        if x == 'the':\n",
    "            indefa += 1\n",
    "            \n",
    "    return ((defa*1.0)/len(set(tokens)), (indefa*1.0)/len(set(tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function computes count of verbs, nouns, adjectives and adverbs in a petition\n",
    "\n",
    "import itertools, nltk\n",
    "from collections import Counter\n",
    "\n",
    "def getpos(text):\n",
    "    tokens = nltk.word_tokenize(text.decode('utf-8','ignore').lower())\n",
    "    text = nltk.Text(tokens)\n",
    "    tags = nltk.pos_tag(text)\n",
    "    counts = Counter(tag for word,tag in tags)\n",
    "    vbc = 0\n",
    "    nnc = 0\n",
    "    rbc = 0\n",
    "    adc = 0\n",
    "    for tag,count in counts.iteritems():\n",
    "        if tag.startswith(\"VB\"):\n",
    "            vbc += 1\n",
    "        if tag.startswith(\"NN\"):\n",
    "            nnc += 1\n",
    "        if tag.startswith(\"JJ\"):\n",
    "            adc += 1\n",
    "        if tag.startswith(\"RB\"):\n",
    "            rbc += 1\n",
    "    return vbc, nnc, adc, rbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function returns named entities in a petition, using which we can get its length\n",
    "\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def get_continuous_chunks(text):\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "    \n",
    "    try:\n",
    "        chunked = ne_chunk(pos_tag(word_tokenize(text.decode('utf-8'))))\n",
    "        prev = None\n",
    "        for i in chunked:\n",
    "            if type(i) == Tree:\n",
    "                current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "            elif current_chunk:\n",
    "                named_entity = \" \".join(current_chunk)\n",
    "                if named_entity not in continuous_chunk:\n",
    "                    continuous_chunk.append(named_entity)\n",
    "                    current_chunk = []\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function computes ratio of pronoun features\n",
    "\n",
    "frst_singular_pronouns = set(['i', 'me', 'mine', 'my'])\n",
    "frst_plural_pronouns = set(['we', 'us', 'our', 'ours'])\n",
    "sec_singular_pronouns = set(['you', 'your', 'yours'])\n",
    "thrd_singular_pronouns = set(['she', 'he', 'it', 'its', 'his', 'her', 'hers'])\n",
    "thrd_plural_pronouns = set(['they', 'them', 'their', 'theirs'])\n",
    "\n",
    "def getpronoun(tokens):\n",
    "    fsp = 0\n",
    "    fpp = 0\n",
    "    ssp = 0\n",
    "    tsp = 0\n",
    "    tpp = 0\n",
    "    for i in tokens:\n",
    "        x = i.lower()\n",
    "        if x in frst_singular_pronouns:\n",
    "            fsp +=1\n",
    "        if x in frst_plural_pronouns:\n",
    "            fpp += 1\n",
    "        if x in sec_singular_pronouns:\n",
    "            ssp += 1\n",
    "        if x in thrd_singular_pronouns:\n",
    "            tsp += 1\n",
    "        if x in thrd_plural_pronouns:\n",
    "            tpp += 1\n",
    "            \n",
    "    return (fsp*1.0)/len(set(tokens)), (fpp*1.0)/len(set(tokens)), (ssp*1.0)/len(set(tokens)), (tsp*1.0)/len(set(tokens)), (tpp*1.0)/len(set(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function computes subjectivity and polarity score based on GI\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import pysentiment as ps\n",
    "hiv4 = ps.HIV4()\n",
    "\n",
    "def getgifeat(tokens):\n",
    "    score = hiv4.get_score(tokens)\n",
    "    return score['Polarity'], score['Subjectivity']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
